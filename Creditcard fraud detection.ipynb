{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26c4669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "load_data=pd.read_csv(\"C:/Users/wissem/Desktop/creditcard/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the shape of the dataset\n",
    "print('The shape of the data set is:',load_data.shape)\n",
    "print('\\n---------------------------------------------\\n')\n",
    "\n",
    "#Check for missing values\n",
    "print('Checking for missing values: \\n')\n",
    "print(pd.isnull(load_data).sum())\n",
    "print('\\n---------------------------------------------\\n')\n",
    "\n",
    "#Load the statistics for the dataset\n",
    "print(load_data.describe())\n",
    "print('\\n---------------------------------------------\\n')\n",
    "\n",
    "#Load the info for the dataset\n",
    "print(load_data.info())\n",
    "print('\\n---------------------------------------------\\n')\n",
    "\n",
    "#Checking if the class is balanced\n",
    "print(load_data['fraud'].value_counts())\n",
    "print('\\n---------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35106d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No fraud (class == 0) meaning legit transactions\n",
    "#Fraud (class == 1) meaning fraudulent transactions\n",
    "\n",
    "#Creating new data frames for No fraud and Fraud cases\n",
    "no_fraud=load_data[load_data.fraud == 0]\n",
    "fraud=load_data[load_data.fraud == 1]\n",
    "\n",
    "#Resampling the original dataset with 10,000 datapoints\n",
    "no_fraud_resample=no_fraud.sample(n=5000)\n",
    "fraud_resample=fraud.sample(n=5000)\n",
    "\n",
    "#Creating new dataset consisting of equal class occurence \n",
    "data=pd.concat([no_fraud_resample,fraud_resample],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe for target\n",
    "target=data['fraud']\n",
    "\n",
    "#Creating dataframe for features\n",
    "features=data.drop(columns=['fraud'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa769c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "train_features,test_features,train_labels,test_labels = train_test_split(features,target,stratify=target,shuffle=True,random_state=43)\n",
    "\n",
    "print('The shape of feature training set is:',train_features.shape)\n",
    "print('The shape of labels training set is:',train_labels.shape)\n",
    "print('The shape of feature testing set is:',test_features.shape)\n",
    "print('The shape of labels testing set is:',test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardising the dataset\n",
    "scale=MinMaxScaler().fit(train_features)\n",
    "train_features_scaled=scale.transform(train_features)\n",
    "test_features_scaled=scale.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list to store model evaluation values\n",
    "data_all=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "m='SVM'\n",
    "model= SVC()\n",
    "param_svm={\n",
    "    \"C\":[100,10,1,0.1],\n",
    "    \"gamma\": [10,1,0.1,0.001],\n",
    "    \"kernel\": ['rbf']\n",
    "    }\n",
    "\n",
    "random_svm=RandomizedSearchCV(estimator=model, param_distributions=param_svm, n_iter = 15 , scoring='accuracy', cv = 10, verbose=2, n_jobs=-1,random_state=43)\n",
    "random_svm.fit(train_features_scaled,train_labels)\n",
    "\n",
    "model=random_svm.best_estimator_\n",
    "crossval = cross_val_score(model,train_features_scaled,train_labels,cv=5,scoring='accuracy')\n",
    "scores = np.mean(crossval)\n",
    "\n",
    "test_pred=model.predict(test_features_scaled)\n",
    "test_recall = recall_score(test_labels, test_pred, pos_label=1)\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, test_pred, pos_label=1)\n",
    "test_auc = auc(fpr, tpr)\n",
    "\n",
    "print('Train acc:',round(scores*100,2),'%')\n",
    "print('Test acc:',round(accuracy_score(test_labels,test_pred)*100,2),'%')\n",
    "print('Best C:',random_svm.best_estimator_.get_params()['C'])\n",
    "print('Best gamma:',random_svm.best_estimator_.get_params()['gamma'])\n",
    "print('Best kernel:',random_svm.best_estimator_.get_params()['kernel']) \n",
    "\n",
    "test_pred=model.predict(test_features_scaled)\n",
    "cm = confusion_matrix(test_labels, test_pred)\n",
    "clr = classification_report(test_labels, test_pred)\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix:SVM\")\n",
    "plt.show()\n",
    "print(\"Classification Report:\\n----------------------\\n\", clr)\n",
    "\n",
    "if accuracy_score(test_labels,test_pred)-scores <1:\n",
    "    result_model='Good Model'\n",
    "    data_all.append([m,scores,accuracy_score(test_labels,test_pred),test_recall,test_auc,result_model])\n",
    "else:\n",
    "    result_model='Failed'\n",
    "    ddata_all.append([m,scores,accuracy_score(test_labels,test_pred),test_recall,test_auc,result_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m='Logistic Regression'\n",
    "model= LogisticRegression(max_iter=1000)\n",
    "param_lr={\n",
    "    \"solver\": ['newton-cg','lbfgs','liblinear'],\n",
    "    \"C\":[100, 10, 1.0, 0.1, 0.01],\n",
    "    \"penalty\":['l2']\n",
    "}\n",
    "random_lr=RandomizedSearchCV(estimator=model, param_distributions=param_lr, n_iter = 15 , scoring='accuracy', cv = 10, verbose=2, n_jobs=-1,random_state=43)\n",
    "random_lr.fit(train_features_scaled,train_labels)\n",
    "model=random_lr.best_estimator_\n",
    "crossval = cross_val_score(model,train_features_scaled,train_labels,cv=5,scoring='accuracy')\n",
    "scores = np.mean(crossval)\n",
    "\n",
    "test_pred=model.predict(test_features_scaled)\n",
    "test_recall = recall_score(test_labels, test_pred, pos_label=1)\n",
    "fpr,tpr,thresholds = roc_curve(test_labels, test_pred, pos_label=1)\n",
    "test_auc = auc(fpr,tpr)\n",
    "\n",
    "print('Train acc:',round(scores*100,2),'%')\n",
    "print('Test acc:',round(accuracy_score(test_labels,test_pred)*100,2),'%')\n",
    "print('Best solver:',random_lr.best_estimator_.get_params()['solver'])\n",
    "print('Best C:',random_lr.best_estimator_.get_params()['C'])\n",
    "print('Best penalty:',random_lr.best_estimator_.get_params()['penalty'])\n",
    "\n",
    "test_pred=model.predict(test_features_scaled)\n",
    "cm = confusion_matrix(test_labels, test_pred)\n",
    "clr = classification_report(test_labels, test_pred)\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix:Log Reg\")\n",
    "plt.show()\n",
    "print(\"Classification Report:\\n----------------------\\n\", clr)\n",
    "\n",
    "if accuracy_score(test_labels,test_pred)-scores <1:\n",
    "    result_model='Good Model'\n",
    "    data_all.append([m,scores,accuracy_score(test_labels,test_pred),test_recall,test_auc,result_model])\n",
    "else:\n",
    "    result_model='Failed'\n",
    "    data_all.append([m,scores,accuracy_score(test_labels,test_pred),test_recall,test_auc,result_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe19e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
